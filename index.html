<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <!-- Primary Meta Tags -->
  <meta name="title" content="WristP²: A Wrist-Worn System for Hand Pose and Pressure Estimation">
  <meta name="description" content="WristP² is a wrist-worn camera system that estimates 3D hand pose and per-vertex pressure from a single wide-FOV RGB frame in real time, achieving 2.9mm MPJPE and 104g pressure MAE.">
  <meta name="keywords" content="Hand Pose Estimation, Pressure Estimation, Human-Computer Interaction, Wearable Devices, Interactive Systems, Computer Vision, Vision Transformer">
  <meta name="author" content="Ziheng Xi, Zihang Ao, Yitao Wang, Mingze Gao, Wanmei Zhang, Jianjiang Feng, Jie Zhou">
  <meta name="robots" content="index, follow">
  <meta name="language" content="English">
  
  <!-- Open Graph / Facebook -->
  <meta property="og:type" content="article">
  <meta property="og:site_name" content="Tsinghua University - Department of Automation">
  <meta property="og:title" content="WristP²: A Wrist-Worn System for Hand Pose and Pressure Estimation">
  <meta property="og:description" content="WristP² is a wrist-worn camera system that estimates 3D hand pose and per-vertex pressure from a single wide-FOV RGB frame in real time, achieving 2.9mm MPJPE and 104g pressure MAE.">
  <meta property="og:url" content="https://wristp2.github.io">
  <meta property="og:image" content="https://wristp2.github.io/static/images/social_preview.png">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:image:alt" content="WristP² - A Wrist-Worn System for Hand Pose and Pressure Estimation - Research Preview">
  <meta property="article:published_time" content="2026-04-13T00:00:00.000Z">
  <meta property="article:author" content="Ziheng Xi">
  <meta property="article:section" content="Research">
  <meta property="article:tag" content="Hand Pose Estimation">
  <meta property="article:tag" content="Pressure Estimation">
  <meta property="article:tag" content="Human-Computer Interaction">
  <meta property="article:tag" content="Wearable Devices">

  <!-- Twitter -->
  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:site" content="@Tsinghua_Uni">
  <meta name="twitter:creator" content="@ZihengXi">
  <meta name="twitter:title" content="WristP²: A Wrist-Worn System for Hand Pose and Pressure Estimation">
  <meta name="twitter:description" content="WristP² is a wrist-worn camera system that estimates 3D hand pose and per-vertex pressure from a single wide-FOV RGB frame in real time, achieving 2.9mm MPJPE and 104g pressure MAE.">
  <meta name="twitter:image" content="https://wristp2.github.io/static/images/social_preview.png">
  <meta name="twitter:image:alt" content="WristP² - A Wrist-Worn System for Hand Pose and Pressure Estimation - Research Preview">

  <!-- Academic/Research Specific -->
  <meta name="citation_title" content="WristP²: A Wrist-Worn System for Hand Pose and Pressure Estimation">
  <meta name="citation_author" content="Xi, Ziheng">
  <meta name="citation_author" content="Ao, Zihang">
  <meta name="citation_author" content="Wang, Yitao">
  <meta name="citation_author" content="Gao, Mingze">
  <meta name="citation_author" content="Zhang, Wanmei">
  <meta name="citation_author" content="Feng, Jianjiang">
  <meta name="citation_author" content="Zhou, Jie">
  <meta name="citation_publication_date" content="2026">
  <meta name="citation_conference_title" content="CHI Conference on Human Factors in Computing Systems">
  <meta name="citation_pdf_url" content="https://wristp2.github.io/static/pdfs/paper.pdf">
  
  <!-- Additional SEO -->
  <meta name="theme-color" content="#2563eb">
  <meta name="msapplication-TileColor" content="#2563eb">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="default">
  
  <!-- Preconnect for performance -->
  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="preconnect" href="https://ajax.googleapis.com">
  <link rel="preconnect" href="https://documentcloud.adobe.com">
  <link rel="preconnect" href="https://cdn.jsdelivr.net">


  <title>WristP²: A Wrist-Worn System for Hand Pose and Pressure Estimation | CHI 2026</title>
  
  <!-- Favicon and App Icons -->
<!-- Favicon and App Icons -->
<link rel="icon" type="image/png" href="static/images/favicon.png?v=2">
<link rel="apple-touch-icon" href="static/images/favicon.png?v=2">
  
  <!-- Critical CSS - Load synchronously -->
  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/index.css">
  
  <!-- Non-critical CSS - Load asynchronously -->
  <link rel="preload" href="static/css/bulma-carousel.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/bulma-slider.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="static/css/fontawesome.all.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <link rel="preload" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css" as="style" onload="this.onload=null;this.rel='stylesheet'">
  
  <!-- Fallback for browsers that don't support preload -->
  <noscript>
    <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  </noscript>
  
  <!-- Fonts - Optimized loading -->
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700;800&display=swap" rel="stylesheet">
  
  <!-- Defer non-critical JavaScript -->
  <script defer src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script defer src="static/js/bulma-carousel.min.js"></script>
  <script defer src="static/js/bulma-slider.min.js"></script>
  <script defer src="static/js/index.js"></script>
  
  <!-- Structured Data for Academic Papers -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "ScholarlyArticle",
    "headline": "WristP²: A Wrist-Worn System for Hand Pose and Pressure Estimation",
    "description": "WristP² is a wrist-worn camera system that estimates 3D hand pose and per-vertex pressure from a single wide-FOV RGB frame in real time, achieving 2.9mm MPJPE and 104g pressure MAE.",
    "author": [
      {
        "@type": "Person",
        "name": "Ziheng Xi",
        "affiliation": {
          "@type": "Organization",
          "name": "Tsinghua University"
        }
      },
      {
        "@type": "Person",
        "name": "Zihang Ao",
        "affiliation": {
          "@type": "Organization",
          "name": "Tsinghua University"
        }
      },
      {
        "@type": "Person",
        "name": "Yitao Wang",
        "affiliation": {
          "@type": "Organization",
          "name": "Tsinghua University"
        }
      },
      {
        "@type": "Person",
        "name": "Mingze Gao",
        "affiliation": {
          "@type": "Organization",
          "name": "Tsinghua University"
        }
      },
      {
        "@type": "Person",
        "name": "Wanmei Zhang",
        "affiliation": {
          "@type": "Organization",
          "name": "Tsinghua University"
        }
      },
      {
        "@type": "Person",
        "name": "Jianjiang Feng",
        "affiliation": {
          "@type": "Organization",
          "name": "Tsinghua University"
        }
      },
      {
        "@type": "Person",
        "name": "Jie Zhou",
        "affiliation": {
          "@type": "Organization",
          "name": "Tsinghua University"
        }
      }
    ],
    "datePublished": "2026-04-13",
    "publisher": {
      "@type": "Organization",
      "name": "ACM"
    },
    "url": "https://wristp2.github.io",
    "image": "https://wristp2.github.io/static/images/social_preview.png",
    "keywords": ["Hand Pose Estimation", "Pressure Estimation", "Human-Computer Interaction", "Wearable Devices", "Interactive Systems", "Computer Vision"],
    "abstract": "Accurate 3D hand pose and pressure sensing is essential for immersive human-computer interaction, yet simultaneously achieving both in mobile scenarios remains a significant challenge. We present WristP², a camera-based wrist-worn system that estimates 3D hand pose and per-vertex pressure from a single wide-FOV RGB frame in real time. A ViT backbone with joint-aligned tokens predicts Hand-VQ-VAE codebook indices for mesh recovery, while an extrinsics-conditioned branch jointly estimates per-vertex pressure. On a self-collected dataset of 133,000 frames (20 subjects; 48 on-plane and 28 mid-air gestures), WristP² attains MPJPE of 2.9mm, Contact IoU of 0.712, Vol. IoU of 0.618, and foreground pressure MAE of 104g.",
    "citation": "@inproceedings{xi2026wristp2, title={WristP²: A Wrist-Worn System for Hand Pose and Pressure Estimation}, author={Xi, Ziheng and Ao, Zihang and Wang, Yitao and Gao, Mingze and Zhang, Wanmei and Feng, Jianjiang and Zhou, Jie}, booktitle={Proceedings of the 2026 CHI Conference on Human Factors in Computing Systems}, year={2026}, organization={ACM}}",
    "isAccessibleForFree": true,
    "license": "https://creativecommons.org/licenses/by/4.0/",
    "mainEntity": {
      "@type": "WebPage",
      "@id": "https://wristp2.github.io"
    },
    "about": [
      {
        "@type": "Thing",
        "name": "Human-Computer Interaction"
      },
      {
        "@type": "Thing", 
        "name": "Computer Vision"
      }
    ]
  }
  </script>
  
  <!-- Website/Organization Structured Data -->
  <script type="application/ld+json">
  {
    "@context": "https://schema.org",
    "@type": "Organization",
    "name": "Tsinghua University - Department of Automation",
    "url": "https://www.tsinghua.edu.cn",
    "logo": "https://wristp2.github.io/static/images/favicon.ico",
    "sameAs": [
      "https://twitter.com/Tsinghua_Uni",
      "https://github.com/tsinghua-university"
    ]
  }
  </script>
<base target="_blank">
</head>
<body>


  <!-- Scroll to Top Button -->
  <button class="scroll-to-top" onclick="scrollToTop()" title="Scroll to top" aria-label="Scroll to top">
    <i class="fas fa-chevron-up"></i>
  </button>

  <!-- More Works Dropdown
  <div class="more-works-container">
    <button class="more-works-btn" onclick="toggleMoreWorks()" title="View More Works from Our Lab">
      <i class="fas fa-flask"></i>
      More Works
      <i class="fas fa-chevron-down dropdown-arrow"></i>
    </button>
    <div class="more-works-dropdown" id="moreWorksDropdown">
      <div class="dropdown-header">
        <h4>More Works from Our Lab</h4>
        <button class="close-btn" onclick="toggleMoreWorks()">
          <i class="fas fa-times"></i>
        </button>
      </div>
      <div class="works-list">
        <a href="https://arxiv.org/abs/2401.00001" class="work-item" target="_blank">
          <div class="work-info">
            <h5>Hand Pose Estimation from Egocentric Views</h5>
            <p>Deep learning approaches for accurate 3D hand reconstruction from wearable cameras.</p>
            <span class="work-venue">CVPR 2024</span>
          </div>
          <i class="fas fa-external-link-alt"></i>
        </a>
        <a href="https://arxiv.org/abs/2305.00001" class="work-item" target="_blank">
          <div class="work-info">
            <h5>Wearable Sensing for Human-Computer Interaction</h5>
            <p>Novel sensing modalities and algorithms for mobile HCI applications.</p>
            <span class="work-venue">UIST 2023</span>
          </div>
          <i class="fas fa-external-link-alt"></i>
        </a>
        <a href="https://arxiv.org/abs/2208.00001" class="work-item" target="_blank">
          <div class="work-info">
            <h5>Vision-Based Pressure Estimation</h5>
            <p>Contact and pressure prediction from visual cues for touch interaction.</p>
            <span class="work-venue">CHI 2023</span>
          </div>
          <i class="fas fa-external-link-alt"></i>
        </a>
      </div>
    </div>
  </div> -->

  <main id="main-content">
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">WristP²: A Wrist-Worn System for Hand Pose and Pressure Estimation</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="mailto:xizh21@mails.tsinghua.edu.cn" target="_blank">Ziheng Xi</a><sup>*</sup>,</span>
                <span class="author-block">
                  <a href="mailto:azh24@mails.tsinghua.edu.cn" target="_blank">Zihang Ao</a><sup>*</sup>,</span>
                  <span class="author-block">
                    <a href="mailto:wangyita23@mails.tsinghua.edu.cn" target="_blank">Yitao Wang</a>,</span>
                  <span class="author-block">
                    <a href="mailto:gaomingze2022@gmail.com" target="_blank">Mingze Gao</a>,</span>
                  <span class="author-block">
                    <a href="mailto:zwm23@mails.tsinghua.edu.cn" target="_blank">Wanmei Zhang</a>,</span>
                  <span class="author-block">
                    <a href="mailto:jfeng@tsinghua.edu.cn" target="_blank">Jianjiang Feng</a>,</span>
                  <span class="author-block">
                    <a href="mailto:jzhou@tsinghua.edu.cn" target="_blank">Jie Zhou</a>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block">Department of Automation, Tsinghua University, Beijing, China<br>CHI '26, April 13-17, 2026, Barcelona, Spain</span>
                    <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span>
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/2502.00000.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                  <span class="link-block">
                    <a href="https://github.com/zhenqis123/WristPP_code" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

<span class="link-block">
  <a href="#" 
     class="external-link button is-normal is-rounded is-dark"
     onclick="alert('Dataset will be released soon. Stay tuned!'); return false;">
    <span class="icon">
      <i class="fas fa-database"></i>
    </span>
    <span>Dataset</span>
  </a>
</span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">

      <figure class="image">
        <img src="static/images/teaser.png" 
             alt="WristP² system overview and interaction scenarios"
             style="width: 100%; border-radius: 12px;">
      </figure>

      <h2 class="subtitle has-text-centered">
        WristP² is a wrist-worn system with a wide-FOV fisheye camera that reconstructs 3D hand pose and per-vertex pressure in real time. Illustrated scenarios include planar input on a virtual surface in XR and controlling slide presentations in mobile scenarios.
      </h2>

    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Accurate 3D hand pose and pressure sensing is essential for immersive human-computer interaction, yet simultaneously achieving both in mobile scenarios remains a significant challenge. We present WristP², a camera-based wrist-worn system that estimates 3D hand pose and per-vertex pressure from a single wide-FOV RGB frame in real time. A ViT (Vision Transformer) backbone with joint-aligned tokens predicts Hand-VQ-VAE codebook indices for mesh recovery, while an extrinsics-conditioned branch jointly estimates per-vertex pressure. On a self-collected dataset of 133,000 frames (20 subjects; 48 on-plane and 28 mid-air gestures), WristP² attains MPJPE (Mean Per-Joint Position Error) of 2.9mm, Contact IoU of 0.712, Vol. IoU of 0.618, and foreground pressure MAE of 10.4g. Across three user studies, WristP² delivers touchpad-level efficiency in mid-air pointing and robust multi-finger pressure control on an uninstrumented desktop. In a real-world large-display Whac-A-Mole task, WristP² also enables higher success ratio and lower arm fatigue than head-mounted camera-based baselines. These results position WristP² as an effective, mobile solution for versatile pose- and pressure-based interaction.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item">
        <img src="static/images/hardware.png" alt="WristP² device with Raspberry Pi Zero 2W and fisheye camera module" loading="lazy"/>
        <h2 class="subtitle has-text-centered">
          WristP² hardware prototype featuring a Raspberry Pi Zero 2W with a wide-FOV fisheye camera module mounted on a watchband.
        </h2>
      </div>
      <div class="item">
        <img src="static/images/pipeline.png" alt="Overall pipeline of the WristP² system" loading="lazy"/>
        <h2 class="subtitle has-text-centered">
          Overall pipeline: ViT backbone with joint-aligned tokens predicts Hand-VQ-VAE codebook indices for mesh recovery, while an extrinsics-conditioned branch jointly estimates per-vertex pressure.
        </h2>
      </div>
      <div class="item">
        <img src="static/images/pose_results.png" alt="Qualitative results showing hand pose estimation" loading="lazy"/>
        <h2 class="subtitle has-text-centered">
          Qualitative results of planar interaction showing accurate 3D hand mesh reconstruction estimation.
        </h2>
     </div>
      <div class="item">
        <img src="static/images/press_results.png" alt="Qualitative results showing hand pressure estimation" loading="lazy"/>
        <h2 class="subtitle has-text-centered">
          Qualitative results of planar interaction showing accurate per-vertex pressure estimation.
        </h2>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->




<!-- Youtube video -->
<section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-3">Video Presentation</h2>

      <div class="columns is-centered">
        <div class="column is-four-fifths">
          <div style="max-width: 900px; margin: 0 auto;">
            <iframe
              src="https://www.youtube.com/embed/TTh29FuKLwQ"
              style="width: 100%; aspect-ratio: 16 / 9; border-radius: 12px;"
              frameborder="0"
              allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
              allowfullscreen>
            </iframe>
          </div>
        </div>
      </div>

    </div>
  </div>
</section>
<!-- End youtube video -->


<!-- Video carousel -->
<!-- <section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Interaction Demos</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="video1" controls muted loop height="100%" preload="metadata">
            <source src="static/videos/carousel1.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <video poster="" id="video2" controls muted loop height="100%" preload="metadata">
            <source src="static/videos/carousel2.mp4" type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video3" controls muted loop height="100%" preload="metadata">
            <source src="static/videos/carousel3.mp4" type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End video carousel -->





<!-- Paper poster -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="chi26c-sub7925-cam-i16.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section> -->
<!--End paper poster -->



<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <div class="bibtex-header">
        <h2 class="title">BibTeX</h2>
        <button class="copy-bibtex-btn" onclick="copyBibTeX()" title="Copy BibTeX to clipboard">
          <i class="fas fa-copy"></i>
          <span class="copy-text">Copy</span>
        </button>
      </div>
      <pre id="bibtex-code"><code>@inproceedings{xi2026wristp2,
  title={WristP²: A Wrist-Worn System for Hand Pose and Pressure Estimation},
  author={Xi, Ziheng and Ao, Zihang and Wang, Yitao and Gao, Mingze and Zhang, Wanmei and Feng, Jianjiang and Zhou, Jie},
  booktitle={Proceedings of the 2026 CHI Conference on Human Factors in Computing Systems},
  year={2026},
  organization={ACM},
  doi={10.1145/3772318.3790626}
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the source code of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>